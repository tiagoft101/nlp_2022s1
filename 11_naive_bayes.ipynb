{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 11: Naive Bayes\n",
    "**Objetivo da aula:** ao fim desta aula, o aluno será capaz de treinar e avaliar um modelo de classificação do tipo Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1\n",
    "*Objetivo: relacionar TF e DF a suas contrapartidas probabilísticas*\n",
    "\n",
    "Complete as frases abaixo:\n",
    "\n",
    "Term Frequency é a quantidade de __________________ em ________________. TF está ligado à probabilidade de, ao escolher aleatoriamente ___________________ entre todos(as) ______________________, encontrar ____________________.\n",
    "\n",
    "Document Frequency é a quantidade de __________________ em ________________. DF está ligado à probabilidade de, ao escolher aleatoriamente ___________________ entre todos(as) ______________________, encontrar ____________________.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2\n",
    "*Objetivo: relacionar eventos e probabilidades ao Teorema de Bayes*\n",
    "\n",
    "O Teorema de Bayes pode ser enunciado como:\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Numa situação fictícia, temos a seguinte situação:\n",
    "* $10\\%$ dos moradores do Bairro do Limoeiro são torcedores do Flamengo\n",
    "* $5\\%$ da população da cidade mora no bairro do limoreiro\n",
    "* $30\\%$ da população da cidade torce para o Flamengo\n",
    "\n",
    "Sabendo que Sam torce para o Flamengo, qual é a probabilidade de Sam morar no Bairro do Limoeiro?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 3\n",
    "*Objetivo: aplicar o Teorema de Bayes para relacionar observações a probabilidades*\n",
    "\n",
    "Uma possível característica de e-mails de spam (mensagens não solicitadas, com conteúdo de propaganda, possíveis golpes, ou malware) é possuir a expressão “WIN”. Porém, nem todos os e-mails de spam possuem a expressão “WIN”, e nem todos os e-mails que possuem a expressão “WIN” são spam.\n",
    "\n",
    "Medindo uma amostra aleatória, contendo tanto e-mails de spam quanto não-spam, encontramos os seguintes dados:\n",
    "*\t10% dos e-mails (selecionados aleatoriamente, incluindo spam e não-spam) contém a expressão “WIN”,\n",
    "*\t1% dos e-mails da coleção são spam (e 99% não são),\n",
    "*\tDos e-mails que são spam, 90% contém a expressão “WIN”,\n",
    "*\tDos e-mails que não são spam, 1% contém a expressão “WIN”.\n",
    "\n",
    "Se, ao selecionarmos um e-mail aleatório, ele contiver a expressão “WIN”, qual é a probabilidade de tratar-se de spam? Qual é a probabilidade de não se tratar de spam?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 4\n",
    "*Objetivo: aplicar o Teorema de Bayes para o caso de múltiplas variáveis independentes*\n",
    "\n",
    "Uma outra característica típica de e-mails tipo “spam” é a presença da palavra “Nigéria”. Na mesma coleção acima, encontramos a palavra “Nigéria” em 95% dos e-mails de spam, mas em apenas 0.1% dos e-mails não-spam. \n",
    "\n",
    "1. Se, ao selecionarmos um e-mail aleatório, ele contiver a palavra “Nigéria”, qual é a probabilidade de tratar-se de spam? Qual é a probabilidade de não se tratar de spam?\n",
    "1. Se um e-mail aleatório contiver, simultaneamente, as palavras “Nigéria” e “WIN”, qual é a probabilidade de tratar-se de spam, assumindo que são probabilidades independentes? Qual é a probabilidade de não se tratar de spam?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 5\n",
    "*Objetivo: analisar um conjunto de dados*\n",
    "\n",
    "Neste exercício, trabalharemos com o \"spam dataset\", disponível no seu material de aula. Usando as técnicas de análise que você já conhece, encontre:\n",
    "\n",
    "1. Quais são as palavras mais comuns em e-mails de spam\n",
    "1. Quais são as palavras mais comuns em e-mails não-spam (ham)\n",
    "1. Qual é a probabilidade de encontrar a palavra “cheap” ao selecionar um documento aleatório entre os e-mails de spam\n",
    "1. Qual é a probabilidade de encontrar a palavra “cheap” ao selecionar um documento aleatório entre os e-mails de não-spam (ham)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/spam_ham_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faça sua análise aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 7\n",
    "*Objetivo: explicar a funcionalidade de dividir a base de dados em conjuntos de treino e teste*\n",
    "\n",
    "No código abaixo, há um exemplo de divisão da base de dados em conjunto de treino e teste.\n",
    "\n",
    "1. Por que devemos dividir nossa base de dados em “treino” e “teste”?\n",
    "1. Qual é o critério para essa divisão quando usamos a função train_test_split()?\n",
    "1. O que o parâmetro random_state faz?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Retirar dados do dataframe\n",
    "textos = list(df['text'])\n",
    "labels = list(df['label'])\n",
    "\n",
    "# 2. Vetorizar\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X = vectorizer.fit_transform(textos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Divisão entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, random_state=37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 8\n",
    "*Objetivo: explicar o processo de treinamento e teste usando BernoulliNB*\n",
    "\n",
    "No código abaixo, usamos um modelo do tipo Bernoulli Naive Bayes.\n",
    "\n",
    "1. Encontre as passagens responsáveis por:\n",
    "    1. Definir e instanciar nosso modelo Naive Bayes\n",
    "    1. Treinar o modelo com dados de treino\n",
    "    1. Executar o modelo com dados de teste\n",
    "    1. Avaliar o modelo\n",
    "\n",
    "1. O que significa o \"Bernoulli\" em \"Bernoulli Naive Bayes\"?\n",
    "1. O que significam os parâmetros fornecidos pelo `classification_report`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Treinamento e teste do modelo\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 9\n",
    "*Objetivo: observar as probabilidades de palavras usadas para classificação*\n",
    "\n",
    "No código abaixo:\n",
    "1. qual é o conteúdo de vectorizer.vocabulary_?\n",
    "1. qual é o conteúdo de model.feature_log_prob?\n",
    "1. por que o modelo usa o logaritmo da probabilidade, não a probabilidade em si?\n",
    "1. observando as palavras mais frequentes em cada classe, como poderíamos melhorar o desempenho do modelo? Realize essa alteração e verifique se o modelo, de fato, melhorou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Qual é o conteúdo de \"vectorizer.vocabulary_\"?\n",
    "vocab = vectorizer.vocabulary_\n",
    "#print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades\n",
    "palavras_ham = []\n",
    "palavras_spam = []\n",
    "for t in vocab.keys():\n",
    "    prob_ham = model.feature_log_prob_[0, vocab[t]]\n",
    "    palavras_ham.append( (prob_ham, t) )\n",
    "    prob_spam = model.feature_log_prob_[1, vocab[t]]\n",
    "    palavras_spam.append( (prob_spam, t) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot das probabilidades\n",
    "# Mostrando num gráfico\n",
    "tuplas_ordenadas = sorted(palavras_ham, reverse=True) # reverse=True pede uma ordenação em ordem decrescente\n",
    "palavras = [ t[1] for t in tuplas_ordenadas ]\n",
    "contagens = [ t[0] for t in tuplas_ordenadas ]\n",
    "\n",
    "n_palavras = 15\n",
    "eixo_x = np.arange(n_palavras)\n",
    "plt.figure(figsize=(14,3))\n",
    "plt.bar(eixo_x[0:n_palavras], contagens[0:n_palavras])\n",
    "plt.xticks(eixo_x[0:n_palavras], palavras[0:n_palavras], rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot das probabilidades\n",
    "# Mostrando num gráfico\n",
    "tuplas_ordenadas = sorted(palavras_spam, reverse=True) # reverse=True pede uma ordenação em ordem decrescente\n",
    "palavras = [ t[1] for t in tuplas_ordenadas ]\n",
    "contagens = [ t[0] for t in tuplas_ordenadas ]\n",
    "\n",
    "n_palavras = 15\n",
    "eixo_x = np.arange(n_palavras)\n",
    "plt.figure(figsize=(14,3))\n",
    "plt.bar(eixo_x[0:n_palavras], contagens[0:n_palavras])\n",
    "plt.xticks(eixo_x[0:n_palavras], palavras[0:n_palavras], rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 10\n",
    "*Objetivo: visualizar a diferença entre probabilidade de ocorrência de palavras e relevância de palavras para classificação*\n",
    "\n",
    "Um problema que existe com Naive Bayes é que a probabilidade de ocorrência de uma palavra nem sempre é o maior determinante de sua importância para classificação. Um exemplo disso é a palavra \"movie\" na classificação de sentimentos do IMDB: ela é comum em ambas as classes, por isso sua presença -- embora contribua bastante para a probabilidade a posteriori do classificador -- não cria diferenças entre as probabilidades relacionadas às classes.\n",
    "\n",
    "1. Que palavras do spam-ham dataset têm alta probabilidade igualmente alta nas duas classes?\n",
    "1. O que acontece com o desempenho do classificador se essas palavras forem removidas do dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 11\n",
    "*Objetivo: implementar um método para evidenciar a relevância de palavras na classificação Naive Bayes*\n",
    "\n",
    "O problema de encontrar relevância de palavras nos classificadores Naive Bayes é bastante conhecido e antigo. Existem várias propostas para isso. Uma delas foi proposta por Chen et al. no artigo:\n",
    "\n",
    "*Jingnian Chen, Houkuan Huang, Shengfeng Tian, Youli Qu, \"Feature selection for text classification with Naïve Bayes\", Expert Systems with Applications, Volume 36, Issue 3, Part 1, 2009, Pages 5432-5435, ISSN 0957-4174, https://doi.org/10.1016/j.eswa.2008.06.054. (https://www.sciencedirect.com/science/article/pii/S0957417408003564))*\n",
    "\n",
    "Nesta proposta, a relevância $r_w$ de uma palavra $w$ é calculada como o módulo da diferença dos logaritmos das probailidades relacionadas a cada palavra, ou seja:\n",
    "\n",
    "$$\n",
    "r_w = 2 | \\log{P( w | \\text{spam})} - \\log{P( w | \\text{ham} ) } |\n",
    "$$\n",
    "\n",
    "Mostre, em um gráfico, quais são as palavras mais relevantes para a classificação de spam e ham em nosso modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolva o exercício aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 12\n",
    "*Objetivo: usar a ideia de classificação para fazer análise de sentimentos*\n",
    "\n",
    "Um problema que é enfrentado atualmente por empresas é a manutenção de reputação em redes sociais. Para isso, as empresas precisam monitorar constantemente o que está sendo dito sobre elas, e é obviamente inviável fazer isso manualmente. Uma solução é ter um pequeno robô que monitora redes sociais e dispara alertas, por exemplo, quando alguém faz um tweet que pode ser interpretado como negativo em relação à empresa ou à indústria.\n",
    "\n",
    "\n",
    "No [Kaggle](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment), há uma base de dados que contém diversos tweets relacionados a linhas aéreas dos Estados Unidos em 2015. Eles estão classificados como “positivo”, “negativo” ou “neutro”, dependendo do conteúdo.\n",
    "\n",
    "1. Programe e avalie um classificador usando Naive Bayes que rotula um tweet como “positivo” ou “negativo” à partir de seu texto.\n",
    "1. Use seu classificador para identificar as palavras mais relevantes para essa classificação\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolva aqui"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
