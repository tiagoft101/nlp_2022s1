{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramatica = \"\"\"\n",
    "FRASE -> SUJEITO PREDICADO\n",
    "SUJEITO -> ENTIDADE\n",
    "PREDICADO -> V OBJETO\n",
    "OBJETO -> ENTIDADE\n",
    "ENTIDADE -> ART N\n",
    "ART -> 'o' | 'a'\n",
    "N -> 'lobo'\n",
    "N -> 'casa'\n",
    "V -> 'soprou'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import CFG\n",
    "from nltk.parse import RecursiveDescentParser\n",
    "\n",
    "grammar = CFG.fromstring(gramatica)\n",
    "parser = RecursiveDescentParser(grammar, trace=0)\n",
    "print(parser.grammar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parser.parse(\"o lobo soprou a casa\".split()):\n",
    " #   print(p)\n",
    "    p.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quem soprou a casa!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pergunta: quem soprou a casa?\n",
    "trees = []\n",
    "for t in parser.parse(\"o lobo soprou a casa\".split()):\n",
    "    trees.append(t)\n",
    "\n",
    "\n",
    "for subtree in trees[0].subtrees(): # Generate all subtrees\n",
    "    if subtree.label()=='SUJEITO':\n",
    "        print(subtree.leaves())\n",
    "\n",
    "# Pergunta: o que o lobo fez?\n",
    "\n",
    "# Pergunta: o que o lobo soprou?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelando ambiguidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PCFG\n",
    "from nltk.parse import InsideChartParser    \n",
    "\n",
    "\n",
    "gramatica = \"\"\"\n",
    "FRASE -> SUJEITO PREDICADO [1]\n",
    "SUJEITO -> ENTIDADE [1]\n",
    "PREDICADO -> V OBJETO [0.5] | V OBJETO ADV [0.5]\n",
    "OBJETO -> ENTIDADE [0.5] | PREP_ART ENTIDADE [0.5]\n",
    "ADV -> PREP ENTIDADE [1]\n",
    "ENTIDADE -> N [0.25] | PROPESS [0.25] | N ADJ [0.5]\n",
    "ADJ -> PREP N [1]\n",
    "PROPESS -> 'ele' [1]\n",
    "V -> 'entrou' [1]\n",
    "PREP_ART -> 'na' [1]\n",
    "N -> 'loja' [0.5]\n",
    "PREP -> 'de' [1]\n",
    "N -> 'calças' [0.5]\n",
    "\"\"\"\n",
    "\n",
    "grammar = PCFG.fromstring(gramatica)\n",
    "parser = InsideChartParser(grammar, trace=0)\n",
    "print(parser.grammar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parser.parse(\"ele entrou na loja de calças\".split()):\n",
    "    p.pretty_print()\n",
    "    print(\"Probability:\", p.prob())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking (ou: parsing com RegEx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partimos de PoS Tags..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o corpus e pré-processar\n",
    "s = open('./datasets/macmorpho-train.txt', 'r', encoding='utf-8').read()\n",
    "s = re.split(r'\\.+_PU', s)\n",
    "s = [s0.strip() for s0 in s]\n",
    "s = [re.split('\\s+', s0) for s0 in s]\n",
    "s = [ [ tuple(re.split('_', w0)) for w0 in p] for p in s]\n",
    "s = [ [ w for w in p if len(w)==2 ] for p in s ] \n",
    "s = [ [ (w[0].lower(), w[1]) for w in p] for p in s ]\n",
    "s = [p for p in s if len(p)>5]      \n",
    "# s[frase][palavra] = (palavra, tipo)\n",
    "#print(s[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import NgramTagger, DefaultTagger\n",
    "taggers = []\n",
    "taggers.append(DefaultTagger('N'))\n",
    "\n",
    "for n in range(3):\n",
    "    taggers.append(NgramTagger(n+1, s, backoff=taggers[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = taggers[-1].tag(\"o porquinho fugiu para a fazenda\".split())\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramatica = ('''\n",
    "    ENTIDADE: {<ART><N>}\n",
    "    PREDICADO: {<V><PREP>?<ENTIDADE>}\n",
    "    SUJEITO: {<ENTIDADE>}\n",
    "    FRASE: {<SUJEITO><PREDICADO>}\n",
    "    ''')\n",
    "parser = nltk.RegexpParser(gramatica)\n",
    "#print(parser)\n",
    "for p in parser.parse(pos):\n",
    "    print(p.pretty_print())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrando entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = taggers[-1].tag(\"o rio de janeiro continua lindo\".split())\n",
    "print(pos)\n",
    "gramatica = ('''\n",
    "    ENTIDADE: {<ART>?<NPROP>}\n",
    "    ''')\n",
    "parser = nltk.RegexpParser(gramatica)\n",
    "#print(parser)\n",
    "for p in parser.parse(pos):\n",
    "    print(p)\n",
    "    #if type(p) != tuple:\n",
    "    #    print(p.leaves())\n",
    "    #if type(p)!=\"<class 'tuple'>\" and p.label()==\"ENTIDADE\":\n",
    "    #    print (p.leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
