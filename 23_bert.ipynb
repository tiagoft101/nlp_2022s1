{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "plt.style.use('default')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baixar o modelo BERT pr√©-treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = Input(shape=(), dtype=tf.string)\n",
    "preprocessor = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",\n",
    "    trainable=False)\n",
    "encoder_inputs = preprocessor(text_input)\n",
    "encoder = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2\",\n",
    "    trainable=False)\n",
    "outputs = encoder(encoder_inputs)\n",
    "pooled_output = outputs[\"pooled_output\"]      # [batch_size, 128].\n",
    "sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 128]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapear frases para embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Model(text_input, pooled_output)\n",
    "sentences = tf.constant([\"Fruit flies like fruits\"])\n",
    "print(embedding_model(sentences)[0][0:30])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Um modelo incorporando BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saida = Dense(2, activation='softmax')(pooled_output)\n",
    "rede_neural = Model(text_input, saida)\n",
    "rede_neural.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "plot_model(rede_neural, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/IMDB Dataset.csv')\n",
    "reviews = list(df['review'])\n",
    "labels = np.array([list(df['sentiment'])]).T\n",
    "ohe = OneHotEncoder()\n",
    "y_ohe = ohe.fit_transform(labels).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, y_ohe, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, restore_best_weights=True)\n",
    "history = rede_neural.fit(tf.convert_to_tensor(X_train), y_train, epochs=500, validation_split=0.2, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est = rede_neural.predict(tf.convert_to_tensor(X_test))\n",
    "print(classification_report(ohe.inverse_transform(y_test), ohe.inverse_transform(y_est)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo com BERT palavra-a-palavra, e LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregador = LSTM(256)(sequence_output)\n",
    "saida = Dense(2, activation='softmax')(agregador)\n",
    "rede_neural = Model(text_input, saida)\n",
    "rede_neural.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "plot_model(rede_neural, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, restore_best_weights=True)\n",
    "history = rede_neural.fit(tf.convert_to_tensor(X_train), y_train, epochs=500, validation_split=0.2, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est = rede_neural.predict(tf.convert_to_tensor(X_test))\n",
    "print(classification_report(ohe.inverse_transform(y_test), ohe.inverse_transform(y_est)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
