{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de treinamento de modelo linguístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['uma', 'frase', 'da', 'minha', 'coleção'], ['outra', 'frase', 'da', 'minha', 'coleção'], ['uma', 'frase', 'nada', 'a', 'ver', 'com', 'as', 'outras']]\n"
     ]
    }
   ],
   "source": [
    "# Passo 1: ter uma coleção de documentos\n",
    "colecao = [\"uma frase da minha coleção\".split(), \"outra frase da minha coleção\".split(), \"uma frase nada a ver com as outras\".split()]\n",
    "print(colecao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('uma',), ('uma', 'frase'), ('frase',), ('frase', 'da'), ('da',), ('da', 'minha'), ('minha',), ('minha', 'coleção'), ('coleção',)], [('outra',), ('outra', 'frase'), ('frase',), ('frase', 'da'), ('da',), ('da', 'minha'), ('minha',), ('minha', 'coleção'), ('coleção',)], [('uma',), ('uma', 'frase'), ('frase',), ('frase', 'nada'), ('nada',), ('nada', 'a'), ('a',), ('a', 'ver'), ('ver',), ('ver', 'com'), ('com',), ('com', 'as'), ('as',), ('as', 'outras'), ('outras',)]]\n",
      "-----\n",
      "[['<s>', 'uma', 'frase', 'da', 'minha', 'coleção', '</s>'], ['<s>', 'outra', 'frase', 'da', 'minha', 'coleção', '</s>'], ['<s>', 'uma', 'frase', 'nada', 'a', 'ver', 'com', 'as', 'outras', '</s>']]\n",
      "-----\n",
      "[[('<s>',), ('<s>', 'uma'), ('uma',), ('uma', 'frase'), ('frase',), ('frase', 'da'), ('da',), ('da', 'minha'), ('minha',), ('minha', 'coleção'), ('coleção',), ('coleção', '</s>'), ('</s>',)], [('<s>',), ('<s>', 'outra'), ('outra',), ('outra', 'frase'), ('frase',), ('frase', 'da'), ('da',), ('da', 'minha'), ('minha',), ('minha', 'coleção'), ('coleção',), ('coleção', '</s>'), ('</s>',)], [('<s>',), ('<s>', 'uma'), ('uma',), ('uma', 'frase'), ('frase',), ('frase', 'nada'), ('nada',), ('nada', 'a'), ('a',), ('a', 'ver'), ('ver',), ('ver', 'com'), ('com',), ('com', 'as'), ('as',), ('as', 'outras'), ('outras',), ('outras', '</s>'), ('</s>',)]]\n"
     ]
    }
   ],
   "source": [
    "# Passo 2: separar minha colecao em n-gramas de tamanho inferior a n\n",
    "from nltk import everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "n = 2\n",
    "\n",
    "# a - encontrar todos os n-gramas de tamanho igual ou menor que N\n",
    "ngramas = [everygrams(c, max_len=n) for c in colecao]\n",
    "print([list (c) for c in ngramas])\n",
    "print(\"-----\")\n",
    "\n",
    "# b - padding para lidar com início e fim de sequências\n",
    "colecao_pad = [pad_both_ends(c, n) for c in colecao]\n",
    "print([list(c) for c in colecao_pad])\n",
    "print(\"-----\")\n",
    "\n",
    "# c- juntar padding com encontrar n-gramas\n",
    "colecao_pad = [pad_both_ends(c, n) for c in colecao]\n",
    "ngramas = [everygrams(c, max_len=n) for c in colecao_pad]\n",
    "print([list (c) for c in ngramas])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'uma', 'frase', 'da', 'minha', 'coleção', '</s>', '<s>', 'outra', 'frase', 'da', 'minha', 'coleção', '</s>', '<s>', 'uma', 'frase', 'nada', 'a', 'ver', 'com', 'as', 'outras', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Passo 3 - encontrar o vocabulário de n-gramas\n",
    "from nltk.lm.preprocessing import flatten\n",
    "\n",
    "colecao_pad = [pad_both_ends(c, n) for c in colecao]\n",
    "ngramas = [everygrams(c, max_len=n) for c in colecao_pad]\n",
    "vocab = flatten(pad_both_ends(c, n) for c in colecao)\n",
    "print(list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 4 - treinar nosso modelo\n",
    "from nltk.lm import MLE \n",
    "\n",
    "lm = MLE(n)\n",
    "colecao_pad = [pad_both_ends(c, n) for c in colecao]\n",
    "ngramas = [everygrams(c, max_len=n) for c in colecao_pad]\n",
    "vocab = flatten(pad_both_ends(c, n) for c in colecao)\n",
    "lm.fit(ngramas, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "---\n",
      "['<s>', 'uma', 'frase', 'da', 'minha', 'coleção', '</s>', 'outra', 'nada', 'a', 'ver', 'com', 'as', 'outras', '<UNK>']\n",
      "---\n",
      "('uma', 'frase')\n",
      "---\n",
      "0.125\n",
      "---\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Passo 5 - visualizar propriedades do modelo\n",
    "print (len(lm.vocab)) # Quantas palavras tem no meu vocabulario\n",
    "print(\"---\")\n",
    "print(list(lm.vocab)) # Quais sao as palavras do meu vocabulario\n",
    "print(\"---\")\n",
    "print(lm.vocab.lookup(\"uma frase\".split())) # Este ngrama faz parte do vocabulario?\n",
    "print(\"---\")\n",
    "print(lm.score(\"frase\")) # Qual é a probabilidade de encontrar esta palavra?\n",
    "print(\"---\")\n",
    "print(lm.score(\"frase\", \"uma\".split())) # Qual é a probabilidade de encontrar esta palavra dado este contexto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "---\n",
      "['<s>', 'uma', 'frase', 'da', 'minha', 'coleção', '</s>', 'outra', 'nada', 'a', 'ver', 'com', 'as', 'outras', '<UNK>']\n",
      "---\n",
      "('uma', 'frase')\n",
      "---\n",
      "0.125\n",
      "---\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Passo 6 - Usar uma API mais condensada para treinar o modelo\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "train_data, vocab = padded_everygram_pipeline(n, colecao)\n",
    "lm = MLE(n)\n",
    "lm.fit(train_data, vocab)\n",
    "\n",
    "print (len(lm.vocab)) # Quantas palavras tem no meu vocabulario\n",
    "print(\"---\")\n",
    "print(list(lm.vocab)) # Quais sao as palavras do meu vocabulario\n",
    "print(\"---\")\n",
    "print(lm.vocab.lookup(\"uma frase\".split())) # Este ngrama faz parte do vocabulario?\n",
    "print(\"---\")\n",
    "print(lm.score(\"frase\")) # Qual é a probabilidade de encontrar esta palavra?\n",
    "print(\"---\")\n",
    "print(lm.score(\"frase\", \"uma\".split())) # Qual é a probabilidade de encontrar esta palavra dado este contexto?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frase nada a ver com as outras </s> outra frase nada a ver com as outras </s> nada a ver\n"
     ]
    }
   ],
   "source": [
    "# Passo 7 - Gerar textos com nosso modelo!\n",
    "texto_ = lm.generate(20, random_seed=27)\n",
    "texto_ = \" \".join(texto_)\n",
    "print(texto_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
