{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/IMDB Dataset.csv').sample(1000)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 2\n",
    "vectorizer = CountVectorizer(binary=True, max_features=400, min_df=0.02, max_df=0.4)\n",
    "X = vectorizer.fit_transform(list(df['review']))\n",
    "print(X.shape)\n",
    "nmf = NMF(n_components=n_components, init='nndsvda')\n",
    "y = nmf.fit_transform(X.toarray())\n",
    "\n",
    "# a1 = nmf.components_[:, vectorizer.vocabulary_['director']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando dados de baixa dimensão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentos e seus tópicos\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(y[:,0], y[:,1], s=1)\n",
    "plt.title('Distribuição de documentos por tópico')\n",
    "plt.ylabel('Tópico 2')\n",
    "plt.xlabel('Tópico 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar cores\n",
    "sent = list(df['sentiment'])\n",
    "yp = np.array([y[i,:] for i in range(len(sent)) if sent[i]=='positive'])\n",
    "yn = np.array([y[i,:] for i in range(len(sent)) if sent[i]=='negative'])\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(yp[:,0], yp[:,1], s=1, c='b', alpha=0.5, label='Positive')\n",
    "plt.scatter(yn[:,0], yn[:,1], s=1, c='r', alpha=0.5, label='Negative')\n",
    "plt.title('Distribuição de documentos por tópico')\n",
    "plt.ylabel('Tópico 2')\n",
    "plt.xlabel('Tópico 1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palavras por tópico\n",
    "v = nmf.components_\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(v[0,:], v[1,:], s=1, c='b')\n",
    "plt.title('Distribuição de palavras por tópico')\n",
    "plt.ylabel('Tópico 2')\n",
    "plt.xlabel('Tópico 1')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando algumas palavras em overlay\n",
    "v = nmf.components_\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(v[0,:], v[1,:], s=1, alpha=0.3, c='b')\n",
    "for s in [\"director\", \"actor\", \"bad\", \"good\", \"excellent\", \"plot\", \"worst\", \"best\", \"terrible\"]:\n",
    "    _n = vectorizer.vocabulary_[s]\n",
    "    plt.text(v[0,_n], v[1,_n], s, ha='center')\n",
    "plt.title('Distribuição de palavras por tópico')\n",
    "plt.ylabel('Tópico 2')\n",
    "plt.xlabel('Tópico 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lidando com dados de dimensão mais alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 60\n",
    "vectorizer = CountVectorizer(binary=True, max_features=400, min_df=0.02, max_df=0.4)\n",
    "X = vectorizer.fit_transform(list(df['review']))\n",
    "print(X.shape)\n",
    "nmf = NMF(n_components=n_components, init='nndsvda')\n",
    "y = nmf.fit_transform(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)\n",
    "y_pca = pca.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar cores\n",
    "sent = list(df['sentiment'])\n",
    "yp = np.array([y_pca[i,:] for i in range(len(sent)) if sent[i]=='positive'])\n",
    "yn = np.array([y_pca[i,:] for i in range(len(sent)) if sent[i]=='negative'])\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(yp[:,0], yp[:,1], s=1, c='b', alpha=0.5, label='Positive')\n",
    "plt.scatter(yn[:,0], yn[:,1], s=1, c='r', alpha=0.5, label='Negative')\n",
    "plt.title('Projeção PCA da distribuição de documentos em tópicos')\n",
    "plt.ylabel('Componente 2')\n",
    "plt.xlabel('Componente 1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição de palavras\n",
    "v = nmf.components_\n",
    "pca2 = PCA(2)\n",
    "v_pca = pca2.fit_transform(v.T).T\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(v_pca[0,:], v_pca[1,:], s=1, alpha=0.3, c='b')\n",
    "for s in [\"director\", \"actor\", \"bad\", \"good\", \"excellent\", \"plot\", \"worst\", \"best\", \"terrible\"]:\n",
    "    _n = vectorizer.vocabulary_[s]\n",
    "    plt.text(v_pca[0,_n], v_pca[1,_n], s, ha='center')\n",
    "plt.title('Projeção PCA da distribuição de palavras por tópico')\n",
    "plt.ylabel('Componente 2')\n",
    "plt.xlabel('Componente 1')\n",
    "plt.xlim([-5,5])\n",
    "plt.ylim([-5,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = Isomap(n_neighbors=5, n_components=2)\n",
    "y_iso = iso.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar cores\n",
    "sent = list(df['sentiment'])\n",
    "yp = np.array([y_iso[i,:] for i in range(len(sent)) if sent[i]=='positive'])\n",
    "yn = np.array([y_iso[i,:] for i in range(len(sent)) if sent[i]=='negative'])\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(yp[:,0], yp[:,1], s=1, c='b', alpha=0.5, label='Positive')\n",
    "plt.scatter(yn[:,0], yn[:,1], s=1, c='r', alpha=0.5, label='Negative')\n",
    "plt.title('Projeção Isomap da distribuição de documentos em tópicos')\n",
    "plt.ylabel('Componente 2')\n",
    "plt.xlabel('Componente 1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição de palavras\n",
    "v = nmf.components_\n",
    "iso2 = Isomap(n_components=2, n_neighbors=5)\n",
    "v_iso = iso2.fit_transform(v.T).T\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(v_iso[0,:], v_iso[1,:], s=1, alpha=0.3, c='b')\n",
    "for s in [\"director\", \"actor\", \"bad\", \"good\", \"excellent\", \"plot\", \"worst\", \"best\", \"terrible\"]:\n",
    "    _n = vectorizer.vocabulary_[s]\n",
    "    plt.text(v_iso[0,_n], v_iso[1,_n], s, ha='center')\n",
    "plt.title('Projeção Isomap da distribuição de palavras por tópico')\n",
    "plt.ylabel('Componente 2')\n",
    "plt.xlabel('Componente 1')\n",
    "#plt.xlim([-20,20])\n",
    "#plt.ylim([-20,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=15)\n",
    "y_tsne = tsne.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar cores\n",
    "sent = list(df['sentiment'])\n",
    "yp = np.array([y_tsne[i,:] for i in range(len(sent)) if sent[i]=='positive'])\n",
    "yn = np.array([y_tsne[i,:] for i in range(len(sent)) if sent[i]=='negative'])\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(yp[:,0], yp[:,1], s=1, c='b', alpha=0.5, label='Positive')\n",
    "plt.scatter(yn[:,0], yn[:,1], s=1, c='r', alpha=0.5, label='Negative')\n",
    "plt.title('Projeção TSNE da distribuição de documentos em tópicos')\n",
    "plt.ylabel('Componente 2')\n",
    "plt.xlabel('Componente 1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição de palavras\n",
    "v = nmf.components_\n",
    "tsne2 = TSNE(n_components=2, perplexity=15)\n",
    "v_tsne2 = tsne2.fit_transform(v.T).T\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(v_tsne2[0,:], v_tsne2[1,:], s=1, alpha=0.3, c='b')\n",
    "for s in [\"director\", \"actor\", \"bad\", \"good\", \"excellent\", \"plot\", \"worst\", \"best\", \"terrible\"]:\n",
    "    _n = vectorizer.vocabulary_[s]\n",
    "    plt.text(v_tsne2[0,_n], v_tsne2[1,_n], s, ha='center')\n",
    "plt.title('Projeção TSNE da distribuição de palavras por tópico')\n",
    "plt.ylabel('Componente 2')\n",
    "plt.xlabel('Componente 1')\n",
    "plt.xlim([-30,30])\n",
    "plt.ylim([-30,30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
