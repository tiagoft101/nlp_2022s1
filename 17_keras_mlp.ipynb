{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "plt.style.use('default')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import Isomap\n",
    "import requests\n",
    "stopwords_list = requests.get(\"https://gist.githubusercontent.com/rg089/35e00abf8941d72d419224cfd5b5925d/raw/12d899b70156fd0041fa9778d657330b024b959c/stopwords.txt\").content\n",
    "stopwords = set(stopwords_list.decode().splitlines()) \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 17: Classificação de Textos com Redes Neurais\n",
    "**Objetivo: ao fim desta aula, o aluno será capaz de programar, treinar e interpretar uma rede neural para classificação de textos usando Keras**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/IMDB Dataset.csv')\n",
    "vectorizer = CountVectorizer(binary=True, stop_words=stopwords, max_features=1000, max_df=0.4)\n",
    "X = vectorizer.fit_transform(list(df['review'])).toarray()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1\n",
    "*Objetivo: analisar um código e suas saídas para entender o que é one-hot encoding*\n",
    "\n",
    "Uma das maneiras de codificar uma saída é através do processo one-hot encoding. Analise o código abaixo e responda:\n",
    "\n",
    "1. Como funciona o \"one-hot encoding\"?\n",
    "1. O que significa cada linha da matriz de one-hot encodings?\n",
    "1. O que significa cada coluna da matriz de one-hot encodings?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "labels = np.array([list(df['sentiment'])]).T\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(labels).toarray()\n",
    "print(type(y))\n",
    "print(y.shape)\n",
    "print(labels[0:5,:])\n",
    "print(y[0:5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2\n",
    "*Objetivo: relacionar a teoria de redes neurais a sua implementação para classificação de textos*\n",
    "\n",
    "A primeira rede neural que implementaremos tem uma entrada X, na mesma forma que estávamos usando no sklearn. A rede neural implementa a equação:\n",
    "\n",
    "$$\n",
    "y=\\sigma(XW)\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "* $y$ é a saída,\n",
    "* $X$ é a entrada,\n",
    "* $W$ é uma matriz\n",
    "* $\\sigma( . )$ é uma função sigmoide\n",
    "\n",
    "A ideia da rede é ter tantas saídas quantas são as possíveis classes em nossos dados. A saída deve ser igual a 1 para a classe “correta”, e 0 para todas as outras classes.\n",
    "\n",
    "1. No caso do IMDB dataset, quantas saídas devemos ter em nossa rede?\n",
    "1. No código abaixo, existe a função `rede_neural_simples`. Ela define um modelo de rede neural. Encontre onde definimos a existência da função sigmoide, e onde definimos que existirá a multiplicação matricial $XW$.\n",
    "1. Lembrando que $X$ é a matriz que marca a presença de uma palavra em cada documento, o que significam as dimensões de W?\n",
    "1. Mais adiante, fazemos o plot da rede. O que significa cada campo desse plot?\n",
    "1. O que a função que define a rede neural retorna? A rede neural executa assim que a função é chamada?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rede_neural_simples(input_dims, n_dims_out):\n",
    "  input_layer = Input(shape=(input_dims,))\n",
    "  x = input_layer\n",
    "  y = Dense(n_dims_out, activation='sigmoid', name='classificador')(x)\n",
    "  return Model(input_layer, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "rede_neural = rede_neural_simples(X.shape[1], y.shape[1])\n",
    "rede_neural.compile(optimizer='adam', loss='mse')\n",
    "plot_model(rede_neural, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 3\n",
    "*Objetivo: treinar uma rede neural simples e analisar as curvas de loss*\n",
    "\n",
    "Execute o processo de treino (fit) da rede neural simples.\n",
    "\n",
    "1. O que é Early Stopping? Por que ele é relevante?\n",
    "1. O que significa dizer que a métrica de erro é `mse` (mean squared error)?\n",
    "1. O que significa dizer que o otimizador é `adam` (adaptive momentum)?\n",
    "1. O que significa o parâmetro `validation_split`?\n",
    "1. O que significa o parâmetro `patience`?\n",
    "1. Como as curvas de `loss` e `val_loss` se comportam? O que isso significa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14956/1582267087.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "history = rede_neural.fit(X_train, y_train, epochs=500, validation_split=0.2, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,2))\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 4\n",
    "*Objetivo: analisar o desempenho da rede neural*\n",
    "\n",
    "Analise o código abaixo, para avaliação da rede neural\n",
    "\n",
    "1. Por que precisamos usar o método `ohe.inverse_transform()` nas saídas da rede neural para usar o `classification_report`?\n",
    "1. Como o desempenho da rede neural se compara com o desempenho das outras estratégias de classificação que já usamos nesta disciplina?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est = rede_neural.predict(X_test)\n",
    "print(y_est[0:5,:])\n",
    "print(y_test[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ohe.inverse_transform(y_test), ohe.inverse_transform(y_est)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 5\n",
    "*Objetivo: analisar os pesos da rede neural*\n",
    "\n",
    "Voltando à equação da rede neural:\n",
    "\n",
    "$$\n",
    "y=\\sigma(XW)\n",
    "$$\n",
    "\n",
    "1. Quantas linhas e colunas deve ter a matriz W?\n",
    "1. O que significa cada elemento $w_{i,j}$?\n",
    "1. Como poderíamos usar a matriz W para entender o quanto cada palavra foi relevante em nosso processo de classificação?\n",
    "1. Verifique o código da seção “que palavras têm mais peso?”. Ele implementa uma ideia parecida com a que você propôs?\n",
    "1. Verifique as palavras que foram encontradas como mais relevantes para a classificação. Esse resultado concorda com o que tivemos para os classificadores anteriores?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = rede_neural.get_layer('classificador').get_weights()\n",
    "#print(w)\n",
    "#print(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização 1: quais são as palavras de maior peso?\n",
    "pesos = np.abs(w[0][:,0] - w[0][:,1])\n",
    "feature_names = vectorizer.get_feature_names() # Modificar isso para versões mais atuais do sklearn\n",
    "pares = [ (pesos[i], feature_names[i]) for i in range(len(feature_names))]\n",
    "pares = sorted(pares, reverse=True)\n",
    "pesos_ = [c[0] for c in pares]\n",
    "palavras_ = [c[1] for c in pares]\n",
    "\n",
    "n_palavras = 50\n",
    "plt.figure(figsize=(14,3))\n",
    "plt.bar(np.arange(n_palavras), pesos_[0:n_palavras])\n",
    "plt.xticks(np.arange(n_palavras), palavras_[0:n_palavras], rotation=80)\n",
    "plt.xlabel('Palavras')\n",
    "plt.ylabel('Peso no classificador')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 6\n",
    "*Objetivo: entender como realizar uma projeção intermediária*\n",
    "\n",
    "Analise o código abaixo, da função `rede_neural_proj`. Ele implementa uma rede neural um pouco diferente da anterior.\n",
    "\n",
    "1. Qual é essa diferença?\n",
    "1. Como ela poderia ser escrita matematicamente (complementando a equação do caso anterior)?\n",
    "1. Houve diferença no desempenho da rede ao adicionar a nova camada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rede_neural_proj(input_dims, n_dims_out):\n",
    "  input_layer = Input(shape=(input_dims,))\n",
    "  x = input_layer\n",
    "  x = Dense(2, name='projecao')(x)\n",
    "  y = Dense(n_dims_out, activation='sigmoid', name='classificador')(x)\n",
    "  return Model(input_layer, y)\n",
    "\n",
    "rede_neural = rede_neural_proj(X.shape[1], y.shape[1])\n",
    "rede_neural.compile(optimizer='adam', loss='mse')\n",
    "plot_model(rede_neural, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "history = rede_neural.fit(X_train, y_train, epochs=500, validation_split=0.2, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,2))\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est = rede_neural.predict(X_test)\n",
    "print(classification_report(ohe.inverse_transform(y_test), ohe.inverse_transform(y_est)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 7\n",
    "*Objetivo: interpretar o espaço latente gerado por uma rede neural com uma camada oculta*\n",
    "\n",
    "1. Quais são as dimensões da matriz da camada `projeção` de nossa rede neural? O que ela está projetando?\n",
    "1. O que você esperaria ver nesse espaço vetorial interno da rede – também chamado de `espaço latente`?\n",
    "1. Analise o código que mostra as projeções intermediárias da rede neural. O que ele mostra? Como devemos interpretá-lo?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização 2: onde foi parar cada palavra?\n",
    "v = rede_neural.get_layer('projecao').get_weights()[0]\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(v[:,0], v[:,1], s=1, alpha=0.3, c='b')\n",
    "for s in [\"director\", \"actor\", \"bad\", \"good\", \"excellent\", \"plot\", \"worst\", \"terrible\", \"waste\", \"awful\", \"fantastic\"]:\n",
    "    _n = vectorizer.vocabulary_[s]\n",
    "    plt.text(v[_n,0], v[_n,1], s, ha='center')\n",
    "plt.title('Projeção das palavras no espaço latente')\n",
    "plt.ylabel('Componente 2')\n",
    "plt.xlabel('Componente 1')\n",
    "#plt.xlim([-20,20])\n",
    "#plt.ylim([-20,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 8\n",
    "*Objetivo: analisar o espaço latente quando aumentamos o tamanho da dimensão latente da rede neural*\n",
    "\n",
    "Se a dimensão do espaço latente da rede neural for maior que dois, é necessário usar alguma técnica de redução de dimensionalidade, como `PCA`, para visualizá-la.\n",
    "\n",
    "O que acontece com as palavras no espaço latente e com o desempenho da rede quando aumentamos a dimensão do espaço latente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
