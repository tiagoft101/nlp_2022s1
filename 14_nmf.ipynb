{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 14: Análise de Tópicos com Fatoração por Matriz Não-Negativa\n",
    "**Objetivo: ao fim desta aula, o aluno será capaz de aplicar análise de tópicos para entender os diferentes assuntos que são comentados em uma coleção**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1\n",
    "*Objetivo: explicar o que é uma matriz de documentos por palavras*\n",
    "\n",
    "No código a seguir:\n",
    "\n",
    "1. O que significa cada linha e cada coluna que compõe a matriz x que foi impressa? \n",
    "1. Existem palavras que, de acordo com a matriz x, tipicamente aparecem juntas em documentos deste corpus? Quais são?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto1 = \"adoro festa junina\"\n",
    "texto2 = \"odeio festa junina\"\n",
    "texto3 = \"big brother brasil é legal\"\n",
    "texto4 = \"big brother brasil é chato\"\n",
    "corpus = [texto1, texto2, texto3, texto4]\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2\n",
    "*Objetivo: explicar o que é uma decomposição com perdas*\n",
    "\n",
    "Em nosso corpus, temos duas categorias de textos: os que falam de festa junina e os que falam de big brother brasil. \n",
    "\n",
    "1. Como seria um vetor correspondente a um documento que tipicamente fala de festa junina?\n",
    "1. E o correspondente a um documento que tipicamente fala de big brother brasil?\n",
    "1. Se usássemos somente esses vetores típicos para cada categoria, ao invés dos documentos em si, que tipo de informação nós conservamos? Que tipo de informação nós perdemos?\n",
    "1. Ao decompor nossos documentos em vetores prototípicos, houve perda de informação? Justifique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 3\n",
    "*Objetivo: aplicar a representação matricial*\n",
    "\n",
    "Em nosso processo de decomposição, partimos de uma matriz X, que é de documentos ($d$) por palavras ($p$), ou: $X_{d,p}$\n",
    "\n",
    "Vamos decompor essa matriz em duas outras matrizes. A primeira delas relaciona documentos a tópicos: $B_{d,t}$\n",
    "\n",
    "Idealmente, qual deveria ser o conteúdo da matriz B em nosso caso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 4\n",
    "*Objetivo: modelar matematicamente a decomposição usando álgebra matricial*\n",
    "\n",
    "Na decomposição, gostaríamos de encontrar duas matrizes que, se forem multiplicadas, podem gerar novamente a matriz original. Então, teremos algo como:\n",
    "X_{d,p}=B_{d,t} A_{?,?}\n",
    "\n",
    "1. Quais devem ser obrigatoriamente as dimensões da matriz A, para que a multiplicação BA seja válida e gere uma matriz com as dimensões de X?\n",
    "1. O que significa cada elemento da matriz A?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 5\n",
    "*Objetivo: explicar o erro na decomposição com perdas*\n",
    "\n",
    "Na decomposição $X=BA$, existem casos em que a multiplicação $BA$ pode não ser igual a $X$. Nesse caso, definimos um erro:\n",
    "\n",
    "$$\n",
    "e = ||X-BA||^2\n",
    "$$\n",
    "\n",
    "Sabemos que o número de documentos ($d$) e de palavras ($p$) depende somente do dataset, isto é, temos controle apenas sobre o número de tópicos $t$.\n",
    "\n",
    "Como o valor de $e$ deve se comportar em relação ao valor de $t$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 6\n",
    "*Objetivo: usar a decomposição do tipo fatoração por matrizes não negativas em nosso toy-corpus*\n",
    "\n",
    "O código abaixo aplica a fatoração por matrizes não-negativas (Non-Negative Matrix Factorization).\n",
    "\n",
    "Ele funciona da seguinte forma:\n",
    "* Recebe X como entrada\n",
    "* Encontra os coeficientes das matrizes $B$ e $A$ minimizando $e = ||X-BA||^2$\n",
    "* Todos os coeficientes devem ser maiores ou iguais a zero\n",
    "\n",
    "\n",
    "1. O que significa o parâmetro n_components? A qual parâmetro ele corresponde na equação do Exercício 4?\n",
    "1. Como devemos interpretar a saída y? A qual parâmetro y corresponde na equação do Exercício 4?\n",
    "1. Os resultados mostrados na saída y correspondem a aquilo que você previu no exercício 3? Por que?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=2, init='nndsvda')\n",
    "y = nmf.fit_transform(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 7\n",
    "*Objetivo: interpretar a representação interna dos componentes em nossa fatoração*\n",
    "\n",
    "Podemos encontrar o último componente restante de nossa fatoração acessando uma variável interna do modelo:\n",
    "`print(nmf.components_)`\n",
    "\n",
    "1. A qual parâmetro da equação do exercício 4 corresponde a matriz em nmf.components_?\n",
    "1. Como devemos interpretar cada um dos parâmetros dela?\n",
    "1. Como seria possível mostrar graficamente o quanto cada palavra participa de cada tópico? (se quiser, veja inspirações em https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nmf.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 8\n",
    "*Objetivo: aplicar o processo de fatoração para visualizar tópicos em uma coleção*\n",
    "\n",
    "Aplique o processo de fatoração por NMF para visualizar, em tópicos, a coleção do IMDB. Use dois tópicos e limite o número de palavras no CountVectorizer em poucas centenas (ou então o NMF vai demorar muito a rodar).\n",
    "\n",
    "Como você interpreta as palavras mais salientes de cada tópico?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/IMDB Dataset.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_palavras = 100\n",
    "n_components = 2\n",
    "vectorizer = CountVectorizer(binary=True, max_features=n_palavras)\n",
    "X = vectorizer.fit_transform(list(df['review']))\n",
    "print(X.shape)\n",
    "nmf = NMF(n_components=n_components, init='nndsvda')\n",
    "y = nmf.fit_transform(X.toarray())\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(n_components):\n",
    "    tuplas = [ (y[vectorizer.vocabulary_[i],n], i) for i in vectorizer.vocabulary_.keys() ]\n",
    "    tuplas_ordenadas = sorted(\n",
    "    tuplas, reverse=True) # reverse=True pede uma ordenação em ordem decrescente\n",
    "    palavras = [ t[1] for t in tuplas_ordenadas ]\n",
    "    contagens = [ t[0] for t in tuplas_ordenadas ]\n",
    "    plt.figure(figsize=(14,3))\n",
    "    eixo_x = np.arange(n_palavras)\n",
    "    plt.bar(eixo_x[0:n_palavras], contagens[0:n_palavras])\n",
    "    plt.xticks(eixo_x[0:n_palavras], palavras[0:n_palavras], rotation=70)\n",
    "    plt.title(\"Topico número \" + str(n))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 9\n",
    "*Objetivo: verificar a correlação entre diferença semântica e distância euclidiana na projeção NMF*\n",
    "\n",
    "A matriz A (que sai em `nmf.components_`) liga cada palavra a um vetor.\n",
    "\n",
    "1. Encontre os vetores ligados às palavras: “director”, “actor” e “excelent”\n",
    "1. Calcule a distância euclidiana entre esses vetores. O que você observa?\n",
    "1. Teste com outros trios de palavras e verifique se essa observação se mantém.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 10\n",
    "*Objetivo: comparar classificadores usando tópicos a classificadores usando palavras*\n",
    "\n",
    "A fatoração faz com que cada palavra seja representada num espaço vetorial de tópicos.\n",
    "\n",
    "Podemos pensar que o espaço vetorial de tópicos pode levar a classificações mais robustas, uma vez que trata-se de um espaço de dimensão mais baixa e cujo significado é compreensível a nós (analistas).\n",
    "\n",
    "Usando o dataset de sua preferência, programe e avalie um classificador que use como entrada a representação das palavras em tópicos, e não mais a entrada do `vectorizer` diretamente.\n",
    "\n",
    "Dica: reveja suas premissas quanto ao significado das dimensões e use um tipo de classificador que corresponde a essas premissas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 11\n",
    "*Objetivo: comparar a distância euclidiana de projeções NMF com a distância em ontologias*\n",
    "\n",
    "Até o momento, fizemos dois tipos de distâncias ou semelhanças que são ligados ao significado de palavras: usando ontologias e usando NMF.\n",
    "\n",
    "Podemos então nos perguntar: \"será que as duas distâncias mostram a mesma coisa?\".\n",
    "\n",
    "Faça um experimento que demonstre se as distâncias baseadas em grafos na Wordnet são redundantes em relação às distâncias obtidas usando NMF.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
