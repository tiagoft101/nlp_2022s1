{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df = pd.read_csv('./datasets/IMDB Dataset.csv')\n",
    "reviews = [s for s in df['review']]\n",
    "sw = stopwords.words('english')\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words=sw, binary=True)\n",
    "x = vectorizer.fit_transform(reviews)\n",
    "x = np.sum(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuplas = [ (x[0,vectorizer.vocabulary_[i]], i) for i in vectorizer.vocabulary_.keys() ]\n",
    "tuplas_ordenadas = sorted(tuplas, reverse=True) # reverse=True pede uma ordenação em ordem decrescente\n",
    "palavras = [ t[1] for t in tuplas_ordenadas ]\n",
    "contagens = [ t[0] for t in tuplas_ordenadas ]\n",
    "\n",
    "n_palavras = 60\n",
    "eixo_x = np.arange(n_palavras)\n",
    "plt.figure(figsize=(14,3))\n",
    "plt.bar(eixo_x[0:n_palavras], contagens[0:n_palavras])\n",
    "plt.xticks(eixo_x[0:n_palavras], palavras[0:n_palavras], rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "reviews = [s for s in df['review']]\n",
    "for n in range (len(reviews)):\n",
    "    reviews[n] = \" \".join([stemmer.stem(p) for p in reviews[n].split()])\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words=sw, binary=True)\n",
    "x = vectorizer.fit_transform(reviews)\n",
    "x = np.sum(x, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuplas = [ (x[0,vectorizer.vocabulary_[i]], i) for i in vectorizer.vocabulary_.keys() ]\n",
    "tuplas_ordenadas = sorted(tuplas, reverse=True) # reverse=True pede uma ordenação em ordem decrescente\n",
    "palavras = [ t[1] for t in tuplas_ordenadas ]\n",
    "contagens = [ t[0] for t in tuplas_ordenadas ]\n",
    "\n",
    "n_palavras = 60\n",
    "eixo_x = np.arange(n_palavras)\n",
    "plt.figure(figsize=(14,3))\n",
    "plt.bar(eixo_x[0:n_palavras], contagens[0:n_palavras])\n",
    "plt.xticks(eixo_x[0:n_palavras], palavras[0:n_palavras], rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "reviews = [s for s in df['review']]\n",
    "for n in range (len(reviews)):\n",
    "    reviews[n] = \" \".join([lemmatizer.lemmatize(p) for p in reviews[n].split()])\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words=sw, binary=True)\n",
    "x = vectorizer.fit_transform(reviews)\n",
    "x = np.sum(x, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuplas = [ (x[0,vectorizer.vocabulary_[i]], i) for i in vectorizer.vocabulary_.keys() ]\n",
    "tuplas_ordenadas = sorted(tuplas, reverse=True) # reverse=True pede uma ordenação em ordem decrescente\n",
    "palavras = [ t[1] for t in tuplas_ordenadas ]\n",
    "contagens = [ t[0] for t in tuplas_ordenadas ]\n",
    "\n",
    "n_palavras = 60\n",
    "eixo_x = np.arange(n_palavras)\n",
    "plt.figure(figsize=(14,3))\n",
    "plt.bar(eixo_x[0:n_palavras], contagens[0:n_palavras])\n",
    "plt.xticks(eixo_x[0:n_palavras], palavras[0:n_palavras], rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"portuguese\")\n",
    "stemmer.stem(\"falante\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RSLPStemmer\n",
    "stemmer = RSLPStemmer()\n",
    "stemmer.stem(\"falante\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
