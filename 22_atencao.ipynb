{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "plt.style.use('default')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import Isomap, TSNE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, TimeDistributed, Embedding, GlobalAveragePooling1D, Flatten, SimpleRNN, GRU, Dropout, LSTM, Bidirectional, Lambda\n",
    "from tensorflow.keras.backend import sum\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©-processar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/IMDB Dataset.csv')\n",
    "reviews = list(df['review'])\n",
    "\n",
    "labels = np.array([list(df['sentiment'])]).T\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(labels).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "sequences = tokenizer.texts_to_sequences(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded = pad_sequences(sequences,maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rede_neural_com_RNN(input_dims, n_dims_out):\n",
    "  input_layer = Input(shape=(input_dims,))\n",
    "  x = input_layer\n",
    "  x = Embedding(1000, 2, name='projecao')(x)\n",
    "  x = LSTM(30)(x)\n",
    "  y = Dense(2, activation='softmax', name='classificador')(x)\n",
    "  return Model(input_layer, y)\n",
    "\n",
    "rede_neural = rede_neural_com_RNN(200, 2)\n",
    "rede_neural.compile(optimizer='adam', loss='mse')\n",
    "plot_model(rede_neural, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "history = rede_neural.fit(X_train, y_train, epochs=50, validation_split=0.2, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est = rede_neural.predict(X_test)\n",
    "print(classification_report(ohe.inverse_transform(y_test), ohe.inverse_transform(y_est)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede com atencao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_atencao(par):\n",
    "  estados, atencao = par[0], par[1]\n",
    "  atencao_aplicada = estados * atencao\n",
    "  contexto = sum(atencao_aplicada, axis=1)\n",
    "  return contexto\n",
    "\n",
    "def rede_neural_com_atencao(input_dims, n_dims_out):\n",
    "  input_layer = Input(shape=(input_dims,))\n",
    "  x = input_layer\n",
    "  x = Embedding(1000, 2, name='projecao')(x)\n",
    "  x = LSTM(30, return_sequences=True)(x)\n",
    "\n",
    "  atencao = TimeDistributed(Dense(1, activation='sigmoid'))(x)\n",
    "  contexto = Lambda(aplicar_atencao)( [x, atencao] )\n",
    "\n",
    "  y = Dense(2, activation='softmax', name='classificador')(contexto)\n",
    "  return Model(input_layer, y), Model(input_layer, atencao)\n",
    "\n",
    "rede_neural, atencao = rede_neural_com_atencao(200, 2)\n",
    "rede_neural.compile(optimizer='adam', loss='mse')\n",
    "plot_model(rede_neural, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "history = rede_neural.fit(X_train, y_train, epochs=50, validation_split=0.2, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est = rede_neural.predict(X_test)\n",
    "print(classification_report(ohe.inverse_transform(y_test), ohe.inverse_transform(y_est)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = atencao.predict(X_test)\n",
    "#print(X_test[0])\n",
    "#print(at[0])\n",
    "words = tokenizer.sequences_to_texts(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words[10].split())\n",
    "len(at[idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=15\n",
    "plt.figure(figsize=(14,2))\n",
    "n_words = len(words[idx].split())\n",
    "at_ = at[idx,-n_words:]\n",
    "plt.plot(at_)\n",
    "plt.xticks(range(n_words), words[idx].split(), rotation=90)\n",
    "plt.xlim([0,90])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede com atencao bidirecional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_atencao(par):\n",
    "  estados, atencao = par[0], par[1]\n",
    "  atencao_aplicada = estados * atencao\n",
    "  contexto = sum(atencao_aplicada, axis=1)\n",
    "  return contexto\n",
    "\n",
    "def rede_neural_com_atencao_bidirecional(input_dims, n_dims_out):\n",
    "  input_layer = Input(shape=(input_dims,))\n",
    "  x = input_layer\n",
    "  x = Embedding(1000, 2, name='projecao')(x)\n",
    "  x_forward = LSTM(30, return_sequences=True)\n",
    "  x_backward = LSTM(30, return_sequences=True, go_backwards=True)\n",
    "  x = Bidirectional(x_forward, backward_layer=x_backward)(x)\n",
    "\n",
    "  atencao = TimeDistributed(Dense(1, activation='sigmoid'))(x)\n",
    "  contexto = Lambda(aplicar_atencao)( [x, atencao] )\n",
    "\n",
    "  y = Dense(2, activation='softmax', name='classificador')(contexto)\n",
    "  return Model(input_layer, y), Model(input_layer, atencao)\n",
    "\n",
    "rede_neural, atencao = rede_neural_com_atencao_bidirecional(200, 2)\n",
    "rede_neural.compile(optimizer='adam', loss='mse')\n",
    "plot_model(rede_neural, show_shapes=True, show_layer_activations=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "history = rede_neural.fit(X_train, y_train, epochs=50, validation_split=0.2, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est = rede_neural.predict(X_test)\n",
    "print(classification_report(ohe.inverse_transform(y_test), ohe.inverse_transform(y_est)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = atencao.predict(X_test)\n",
    "#print(X_test[0])\n",
    "#print(at[0])\n",
    "words = tokenizer.sequences_to_texts(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words[10].split())\n",
    "len(at[idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=88\n",
    "plt.figure(figsize=(14,2))\n",
    "n_words = len(words[idx].split())\n",
    "at_ = at[idx,-n_words:]\n",
    "plt.plot(at_)\n",
    "plt.xticks(range(n_words), words[idx].split(), rotation=90)\n",
    "plt.xlim([0,90])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
